{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9183228-0ba6-4af9-8430-649e28868253",
   "metadata": {
    "id": "JMXGlIvAwn30"
   },
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Chain of Thought\n",
    "We will use a variation of this technique by explicitly structuring our questions to guide the reasoning process. Before applying it, we will first verify that the API functions correctly."
   ],
   "id": "5dd2a0022beefa14"
  },
  {
   "cell_type": "code",
   "id": "f5308d65",
   "metadata": {
    "height": 319,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-31T21:45:15.509744Z",
     "start_time": "2025-01-31T21:45:12.742178Z"
    }
   },
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "import helper.creden as cre\n",
    "client = OpenAI(api_key=cre.OPENAI_API_KEY)\n",
    "from helper.helper import parse_conversation, select_random_test, get_completion_from_messages\n",
    "\n",
    "# widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "client = OpenAI(api_key=cre.OPENAI_API_KEY)\n",
    "model_selection=\"gpt-4o-mini\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:45:17.234964Z",
     "start_time": "2025-01-31T21:45:15.515278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages_verification=[{\"role\": \"user\", \"content\": \"Are you working?\"}]\n",
    "result = get_completion_from_messages(messages = messages_verification, model = model_selection, temperature=0.8, max_tokens_values=4)\n",
    "result"
   ],
   "id": "abf423b94ad1bf00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm here\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have confirmed the API is working, we will conduct an experiment.",
   "id": "70b78dea5a53fe33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:45:17.251053Z",
     "start_time": "2025-01-31T21:45:17.237165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tests_interviews = {\n",
    "                \"topics\": [\n",
    "                    {\n",
    "                    \"name\": \"Predictive Modeling\",\n",
    "                    \"example\": \"Predicting customer churn for a subscription service.\",\n",
    "                    \"problem\": \"Identifying which customers are likely to stop using the service and why.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Recommendation Systems\",\n",
    "                    \"example\": \"Suggesting products on an e-commerce platform.\",\n",
    "                    \"problem\": \"Providing personalized recommendations to improve user engagement and sales.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Natural Language Processing (NLP)\",\n",
    "                    \"example\": \"Sentiment analysis on customer reviews.\",\n",
    "                    \"problem\": \"Understanding customer sentiment to improve product offerings or service quality.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Time Series Analysis\",\n",
    "                    \"example\": \"Forecasting monthly sales for inventory planning.\",\n",
    "                    \"problem\": \"Predicting demand accurately to avoid stockouts or overstocking.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Anomaly Detection\",\n",
    "                    \"example\": \"Detecting fraudulent transactions in banking systems.\",\n",
    "                    \"problem\": \"Identifying unusual patterns or behaviors that indicate fraud.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Image and Video Analytics\",\n",
    "                    \"example\": \"Detecting defects in manufacturing products using image classification.\",\n",
    "                    \"problem\": \"Automating quality control to reduce manual inspection errors.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Customer Segmentation\",\n",
    "                    \"example\": \"Grouping customers by purchasing behavior.\",\n",
    "                    \"problem\": \"Creating targeted marketing campaigns to boost conversion rates.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Optimization Models\",\n",
    "                    \"example\": \"Optimizing delivery routes for a logistics company.\",\n",
    "                    \"problem\": \"Minimizing fuel costs and delivery time.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"A/B Testing\",\n",
    "                    \"example\": \"Testing two website layouts to improve user conversion.\",\n",
    "                    \"problem\": \"Determining which design leads to better engagement or sales.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Big Data Processing\",\n",
    "                    \"example\": \"Analyzing clickstream data from millions of users on a streaming platform.\",\n",
    "                    \"problem\": \"Deriving insights and recommendations from massive, unstructured datasets.\"\n",
    "                    }\n",
    "                ]\n",
    "                }\n",
    "# select a random test\n",
    "random_topic = select_random_test(tests_interviews)\n",
    "random_topic"
   ],
   "id": "e505a80c39576cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Predictive Modeling',\n",
       " 'example': 'Predicting customer churn for a subscription service.',\n",
       " 'problem': 'Identifying which customers are likely to stop using the service and why.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "89d1f0e91d3fef34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt generation",
   "id": "de87d507af361a44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:45:17.266912Z",
     "start_time": "2025-01-31T21:45:17.253052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chain-of-Thought Prompting: \n",
    "prompt_example = f\"\"\"\n",
    "We are conducting a data science interview focused exclusively on \n",
    "data science topics. Avoid discussing unrelated subjects. Ensure\n",
    "a rigorous and structured interview process with the goal of \n",
    "evaluating the candidate's expertise in data science. Allocate\n",
    "2 points for each well-answered question, and maintain high \n",
    "expectations as a data science professional with 5 years of\n",
    "experience. Look for key terminology and concepts relevant\n",
    "to the field.\n",
    "\n",
    "Steps to Follow:\n",
    "Introduction: Begin with a brief introduction of the company. Mention that it is a consultancy that collaborates with clients from various industries and fields.\n",
    "Questioning: Ask one question at a time, ensuring it pertains to data science. Move on to the next question only after receiving an answer.\n",
    "Example Problem: Incorporate this field example {random_topic[\"example\"]} and this problem {random_topic[\"problem\"]} as a case study to keep the discussion grounded.\n",
    "Dataset Creation: Design a simple dataset with 5 rows and 4–8 features, including a target variable, to use as part of the problem-solving exercise. Present this dataset in a table format.\n",
    "this its the example of the dataset\n",
    "Question Design: Formulate one thoughtful question at a time based on the dataset or case study. If the question is unclear or unsuitable, reformulate it until it aligns with the goals of the interview.\n",
    "Scoring: Assign a score from 0 to 9 for each response, where 9 represents expert-level knowledge. Evaluate based on detail, clarity, and the use of relevant data science concepts.\n",
    "Conclusion: Conclude by thanking the candidate for their time and providing an overall score based on their performance.\n",
    "Feedback: After completing all questions, identify areas where the interview process could be improved, providing specific points for enhancement.\n",
    "Final Output: Summarize the results in a JSON format, including the overall score and interview feedback.\n",
    "\n",
    "Reminder: Ensure the questions and evaluations are rigorous, leveraging your data science expertise to assess technical depth and problem-solving abilities.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "context = [{'role':'system', 'content':prompt_example}]\n",
    "context"
   ],
   "id": "e59b56759644943c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nWe are conducting a data science interview focused exclusively on \\ndata science topics. Avoid discussing unrelated subjects. Ensure\\na rigorous and structured interview process with the goal of \\nevaluating the candidate's expertise in data science. Allocate\\n2 points for each well-answered question, and maintain high \\nexpectations as a data science professional with 5 years of\\nexperience. Look for key terminology and concepts relevant\\nto the field.\\n\\nSteps to Follow:\\nIntroduction: Begin with a brief introduction of the company. Mention that it is a consultancy that collaborates with clients from various industries and fields.\\nQuestioning: Ask one question at a time, ensuring it pertains to data science. Move on to the next question only after receiving an answer.\\nExample Problem: Incorporate this field example Predicting customer churn for a subscription service. and this problem Identifying which customers are likely to stop using the service and why. as a case study to keep the discussion grounded.\\nDataset Creation: Design a simple dataset with 5 rows and 4–8 features, including a target variable, to use as part of the problem-solving exercise. Present this dataset in a table format.\\nthis its the example of the dataset\\nQuestion Design: Formulate one thoughtful question at a time based on the dataset or case study. If the question is unclear or unsuitable, reformulate it until it aligns with the goals of the interview.\\nScoring: Assign a score from 0 to 9 for each response, where 9 represents expert-level knowledge. Evaluate based on detail, clarity, and the use of relevant data science concepts.\\nConclusion: Conclude by thanking the candidate for their time and providing an overall score based on their performance.\\nFeedback: After completing all questions, identify areas where the interview process could be improved, providing specific points for enhancement.\\nFinal Output: Summarize the results in a JSON format, including the overall score and interview feedback.\\n\\nReminder: Ensure the questions and evaluations are rigorous, leveraging your data science expertise to assess technical depth and problem-solving abilities.\\n\\n\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T21:53:15.878525Z",
     "start_time": "2025-01-31T21:53:15.845429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create text box for user input\n",
    "user_input = widgets.Textarea(value='',\n",
    "                              placeholder='Enter text here...',\n",
    "                              description='User:',\n",
    "                              rows=2,\n",
    "                              layout=widgets.Layout(width='auto'),\n",
    "                              disabled=False)\n",
    "\n",
    "# Create text area for conversation display\n",
    "conversation_history = widgets.Textarea(value='',\n",
    "                                        description='Chat:',\n",
    "                                     rows=15,\n",
    "                                        layout=widgets.Layout(width='auto'))\n",
    "\n",
    "# Create button for user to click to send their message\n",
    "send_button = widgets.Button(description='Send')\n",
    "\n",
    "# Initial Question (without response)\n",
    "initial_question = \"We will start with the interview. Can you give me a brief introduction about yourself?\"\n",
    "conversation_history.value += 'assistant: ' + initial_question + '\\n'\n",
    "context.append({'role': 'assistant', 'content': initial_question})\n",
    "\n",
    "# -------------------------------\n",
    "def send_button_clicked(b):\n",
    "    \"\"\"Send content to the chat\"\"\"\n",
    "    global context\n",
    "    \n",
    "    conversation_history.value += 'user: ' + user_input.value + '\\n'\n",
    "    context.append({'role': 'user', 'content': user_input.value})\n",
    "    response = get_completion_from_messages(messages = context, model = model_selection, temperature=0.1, max_tokens_values=2000)\n",
    "    conversation_history.value += 'assistant: ' + response + '\\n'\n",
    "    context.append({'role': 'assistant', 'content': response})\n",
    "    user_input.value = ''\n",
    "    \n",
    "# -------------------------------\n",
    "send_button.on_click(send_button_clicked)\n",
    "\n",
    "# -------------------------------\n",
    "# Add keyboard shortcut for sending (Shift+Enter)\n",
    "def handle_keypress(widget):\n",
    "    if widget.value.endswith('\\n'):\n",
    "        send_button_clicked(None)\n",
    "        \n",
    "user_input.observe(handle_keypress, names='value')\n",
    "# -------------------------------\n",
    "# Display everything\n",
    "display(conversation_history, user_input, send_button)"
   ],
   "id": "f49c7e99c4571577",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Textarea(value='assistant: We will start with the interview. Can you give me a brief introduction about yourse…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ad99bdad8204b1db9ef05e4b2cf2c19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(width='auto'), placeholder='Enter text here...', rows=2)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "637052401b954a36921996ff51094bce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(description='Send', style=ButtonStyle())"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a71da51cd1124f4ab0a05ff7dc812b40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Review of the interaction",
   "id": "385f0a78a78ace52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:00:02.657480Z",
     "start_time": "2025-01-31T22:00:02.639353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_result = parse_conversation(conversation_history.value)\n",
    "print(json.dumps(json_result, indent=2))"
   ],
   "id": "1c0af0bc29efab75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"conversation\": [\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"We will start with the interview. Can you give me a brief introduction about yourself?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Im roishin\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you, Roishin. I appreciate your introduction.\\nLet me provide a brief overview of our company. We are a consultancy that collaborates with clients from various industries and fields, leveraging data science to drive insights and improve decision-making.\\nNow, let's dive into the interview.\\n**Question 1:** Can you explain the concept of customer churn and why it is important for businesses to predict it?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"refers to the percentage of cutomers(cx) who stop using a product or service over a given period\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Roishin. You correctly defined customer churn as the percentage of customers who discontinue using a product or service over a specific time frame.\\nTo expand on your answer, predicting customer churn is important for businesses because it allows them to identify at-risk customers, understand the reasons behind their potential departure, and implement strategies to retain them. This can lead to improved customer satisfaction, reduced acquisition costs, and ultimately, increased revenue.\\n**Score for Question 1:** 5/9\\nLet's move on to the next part of our discussion.\\n**Dataset Creation:** Here is a simple dataset that we will use for our case study on predicting customer churn for a subscription service:\\n| CustomerID | Age | MonthlySpend | SubscriptionLength (months) | Churned (Target) |\\n|------------|-----|--------------|------------------------------|-------------------|\\n| 1          | 25  | 30           | 12                           | 0                 |\\n| 2          | 34  | 45           | 6                            | 1                 |\\n| 3          | 29  | 20           | 24                           | 0                 |\\n| 4          | 42  | 50           | 3                            | 1                 |\\n| 5          | 31  | 35           | 18                           | 0                 |\\n**Question 2:** Based on this dataset, what features do you think are most relevant for predicting customer churn, and why?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"no idea\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your honesty, Roishin. It's important to recognize when you're unsure about a topic.\\nIn the context of the dataset provided, some relevant features for predicting customer churn could include:\\n1. **MonthlySpend:** This feature can indicate customer engagement; higher spending may correlate with higher satisfaction and lower churn.\\n2. **SubscriptionLength:** Longer subscription lengths might suggest loyalty, making it a critical feature for churn prediction.\\n3. **Age:** Depending on the service, age could influence spending habits and preferences, potentially impacting churn rates.\\nUnderstanding the relevance of these features is crucial for building an effective predictive model.\\n**Score for Question 2:** 2/9\\nLet's proceed to the next question.\\n**Question 3:** What steps would you take to preprocess this dataset before applying a machine learning model? Please outline the key preprocessing techniques you would consider.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"We will try to check for missing values, null values feature encoding and feature enginiering to add new features\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Roishin. You mentioned several important preprocessing steps, which is a good start. Here\\u2019s a more detailed breakdown of the preprocessing techniques you outlined:\\n1. **Checking for Missing Values:** Identifying any missing data points is crucial. You can handle them by either removing those rows, imputing values, or using techniques like mean/mode imputation.\\n2. **Null Values:** This is similar to checking for missing values, but it\\u2019s important to ensure that any null entries are addressed appropriately.\\n3. **Feature Encoding:** If there are categorical variables (though in this dataset, all features are numerical), you would need to convert them into a numerical format using techniques like one-hot encoding or label encoding.\\n4. **Feature Engineering:** This involves creating new features from existing ones that may provide additional insights. For example, you could create a feature that represents the ratio of MonthlySpend to SubscriptionLength.\\n5. **Feature Scaling:** Normalizing or standardizing numerical features can help improve the performance of certain algorithms.\\nYour answer shows a good understanding of the preprocessing steps, but providing more detail on each step would enhance your response.\\n**Score for Question 3:** 6/9\\nNow, let's move on to the next question.\\n**Question 4:** Once you have preprocessed the data, which machine learning algorithms would you consider for predicting customer churn, and why would you choose those specific algorithms?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"Xgboos, logistic regression or SVM to name a few\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Roishin. You mentioned several strong algorithms for predicting customer churn, which is a good approach.\\n1. **XGBoost:** This is an excellent choice due to its efficiency and performance with structured data. It handles missing values well and is robust against overfitting, making it suitable for many classification tasks.\\n2. **Logistic Regression:** This algorithm is valuable for its interpretability and effectiveness in binary classification problems. It provides insights into the relationship between features and the likelihood of churn.\\n3. **Support Vector Machines (SVM):** SVMs are effective in high-dimensional spaces and can be useful for classification tasks, especially when the classes are not linearly separable.\\nIt would also be beneficial to mention other algorithms, such as Random Forest, which can provide feature importance and handle non-linear relationships, or Neural Networks, which can capture complex patterns in the data.\\nOverall, your answer demonstrates a solid understanding of machine learning algorithms relevant to churn prediction.\\n**Score for Question 4:** 7/9\\nNow, let's move on to the final question.\\n**Question 5:** After training your model, how would you evaluate its performance? What metrics would you use, and why are they important in the context of customer churn prediction?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"using a F1 score for the model but for comparing different models we can use ROCAUC for reading in between models\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Roishin. You correctly identified the F1 score as a valuable metric for evaluating model performance, especially in the context of customer churn prediction. The F1 score balances precision and recall, which is crucial when the cost of false negatives (failing to identify a churned customer) can be significant.\\nYou also mentioned using ROC AUC (Receiver Operating Characteristic Area Under the Curve) for comparing different models. This is an excellent choice, as it provides insight into the trade-off between true positive rates and false positive rates across various thresholds, allowing for a comprehensive comparison of model performance.\\nIn addition to these metrics, it could be beneficial to mention:\\n- **Accuracy:** While it may not be the best metric in imbalanced datasets, it can still provide a general sense of model performance.\\n- **Confusion Matrix:** This can help visualize the performance of the model in terms of true positives, false positives, true negatives, and false negatives.\\nYour answer demonstrates a good understanding of model evaluation metrics.\\n**Score for Question 5:** 7/9\\n**Conclusion:** Thank you for your time today, Roishin. Based on your performance throughout the interview, your overall score is **5.8/9**.\\n**Feedback:**\\n- You demonstrated a solid understanding of key concepts, particularly in the areas of churn prediction and model evaluation.\\n- There were gaps in your knowledge regarding feature relevance and preprocessing techniques, which are critical in the data science workflow.\\n- I recommend further study on data preprocessing techniques and a broader understanding of machine learning algorithms and their applications.\\n**Final Output:**\\n```json\\n{\\n  \\\"overall_score\\\": 5.8,\\n  \\\"interview_feedback\\\": {\\n    \\\"strengths\\\": [\\n      \\\"Understanding of customer churn and its importance.\\\",\\n      \\\"Knowledge of evaluation metrics like F1 score and ROC AUC.\\\"\\n    ],\\n    \\\"areas_for_improvement\\\": [\\n      \\\"Feature relevance in churn prediction.\\\",\\n      \\\"More detailed knowledge of data preprocessing techniques.\\\",\\n      \\\"Broader knowledge of machine learning algorithms.\\\"\\n    ]\\n  }\\n}\\n```\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"nice\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"I'm glad you found the interview process and feedback helpful! If you have any further questions or if there's anything else you'd like to discuss regarding data science or related topics, feel free to ask. Thank you for your participation!\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"we can talk about coffe\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"I appreciate your interest, but let's keep our focus on data science topics. If you have any more questions or topics related to data science, machine learning, or analytics, feel free to ask!\"\n",
      "    }\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"interview_topic\": \"Delivery Route Optimization\",\n",
      "    \"interview_results\": {}\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:01:01.341447Z",
     "start_time": "2025-01-31T22:01:01.312892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pattern = r'\\*\\*Final Output:\\*\\*\\s*```json\\s*({.*?})\\s*```'\n",
    "\n",
    "match = re.search(pattern, conversation_history.value, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    extracted_data = match.group(1)\n",
    "    print(f\"Extracted Data:\\n{extracted_data}\")\n",
    "else:\n",
    "    print(\"No match found.\")"
   ],
   "id": "815f0af815a86f80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:\n",
      "{\n",
      "  \"overall_score\": 5.8,\n",
      "  \"interview_feedback\": {\n",
      "    \"strengths\": [\n",
      "      \"Understanding of customer churn and its importance.\",\n",
      "      \"Knowledge of evaluation metrics like F1 score and ROC AUC.\"\n",
      "    ],\n",
      "    \"areas_for_improvement\": [\n",
      "      \"Feature relevance in churn prediction.\",\n",
      "      \"More detailed knowledge of data preprocessing techniques.\",\n",
      "      \"Broader knowledge of machine learning algorithms.\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In this case, the model first reasons through the response and then assigns a score based on its evaluation. This approach ensures that the score is justified and directly linked to the accuracy and relevance of the answer.",
   "id": "c06f2c718280608c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
