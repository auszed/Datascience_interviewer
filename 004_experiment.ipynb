{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9183228-0ba6-4af9-8430-649e28868253",
   "metadata": {
    "id": "JMXGlIvAwn30"
   },
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Generated Knowledge & Maieutic Prompting\n",
    "\n",
    "In this case, we will be applying these two methods to improve the model performance.\n",
    "\n",
    "We used the \"Generated Knowledge\" to create structured, expert-level data science questions based on known concepts. Maieutic Prompting is applied through iterative questioning, response refinement, and feedback to ensure a rigorous evaluation process."
   ],
   "id": "5dd2a0022beefa14"
  },
  {
   "cell_type": "code",
   "id": "f5308d65",
   "metadata": {
    "height": 319,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-01-31T22:20:02.148819Z",
     "start_time": "2025-01-31T22:19:59.558413Z"
    }
   },
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "import helper.creden as cre\n",
    "client = OpenAI(api_key=cre.OPENAI_API_KEY)\n",
    "from helper.helper import parse_conversation, select_random_test, get_completion_from_messages\n",
    "\n",
    "# widgets\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "client = OpenAI(api_key=cre.OPENAI_API_KEY)\n",
    "model_selection=\"gpt-4o-mini\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:20:03.845935Z",
     "start_time": "2025-01-31T22:20:02.151335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "messages_verification=[{\"role\": \"user\", \"content\": \"Are you working?\"}]\n",
    "result = get_completion_from_messages(messages = messages_verification, model = model_selection, temperature=0.8, max_tokens_values=4)\n",
    "result"
   ],
   "id": "abf423b94ad1bf00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm here\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now that we have confirmed the API is working, we will conduct an experiment.",
   "id": "70b78dea5a53fe33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:20:03.877413Z",
     "start_time": "2025-01-31T22:20:03.851505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tests_interviews = {\n",
    "                \"topics\": [\n",
    "                    {\n",
    "                    \"name\": \"Predictive Modeling\",\n",
    "                    \"example\": \"Predicting customer churn for a subscription service.\",\n",
    "                    \"problem\": \"Identifying which customers are likely to stop using the service and why.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Recommendation Systems\",\n",
    "                    \"example\": \"Suggesting products on an e-commerce platform.\",\n",
    "                    \"problem\": \"Providing personalized recommendations to improve user engagement and sales.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Natural Language Processing (NLP)\",\n",
    "                    \"example\": \"Sentiment analysis on customer reviews.\",\n",
    "                    \"problem\": \"Understanding customer sentiment to improve product offerings or service quality.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Time Series Analysis\",\n",
    "                    \"example\": \"Forecasting monthly sales for inventory planning.\",\n",
    "                    \"problem\": \"Predicting demand accurately to avoid stockouts or overstocking.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Anomaly Detection\",\n",
    "                    \"example\": \"Detecting fraudulent transactions in banking systems.\",\n",
    "                    \"problem\": \"Identifying unusual patterns or behaviors that indicate fraud.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Image and Video Analytics\",\n",
    "                    \"example\": \"Detecting defects in manufacturing products using image classification.\",\n",
    "                    \"problem\": \"Automating quality control to reduce manual inspection errors.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Customer Segmentation\",\n",
    "                    \"example\": \"Grouping customers by purchasing behavior.\",\n",
    "                    \"problem\": \"Creating targeted marketing campaigns to boost conversion rates.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Optimization Models\",\n",
    "                    \"example\": \"Optimizing delivery routes for a logistics company.\",\n",
    "                    \"problem\": \"Minimizing fuel costs and delivery time.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"A/B Testing\",\n",
    "                    \"example\": \"Testing two website layouts to improve user conversion.\",\n",
    "                    \"problem\": \"Determining which design leads to better engagement or sales.\"\n",
    "                    },\n",
    "                    {\n",
    "                    \"name\": \"Big Data Processing\",\n",
    "                    \"example\": \"Analyzing clickstream data from millions of users on a streaming platform.\",\n",
    "                    \"problem\": \"Deriving insights and recommendations from massive, unstructured datasets.\"\n",
    "                    }\n",
    "                ]\n",
    "                }\n",
    "# select a random test\n",
    "random_topic = select_random_test(tests_interviews)\n",
    "random_topic"
   ],
   "id": "e505a80c39576cc5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'A/B Testing',\n",
       " 'example': 'Testing two website layouts to improve user conversion.',\n",
       " 'problem': 'Determining which design leads to better engagement or sales.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "89d1f0e91d3fef34"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompt generation",
   "id": "de87d507af361a44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:20:18.237476Z",
     "start_time": "2025-01-31T22:20:18.221444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Chain-of-Thought Prompting: \n",
    "prompt_example = f\"\"\"\n",
    "We are conducting a data science interview focused exclusively on \n",
    "data science topics. Avoid discussing unrelated subjects. Ensure\n",
    "a rigorous and structured interview process with the goal of \n",
    "evaluating the candidate's expertise in data science. ask just 3 question in each interview as much\n",
    "for each well-answered question, and maintain high \n",
    "expectations as a data science professional with 5 years of\n",
    "experience. Look for key terminology and concepts relevant\n",
    "to the field.\n",
    "\n",
    "---------------\n",
    "Generated Knowledge Example Question: \n",
    "- We are working with a healthcare company to predict the likelihood of patients being readmitted within 30 days of discharge. The dataset includes patient demographics, medical history, and various other details related to their hospital stay. What steps would you take to build a model for this prediction task?\n",
    "- You’ve chosen a random forest model for predicting house prices. Could you explain what might happen if the model starts overfitting the data? What steps would you take to mitigate overfitting in this case, and how would you determine if the model is truly generalizing well?\n",
    "\n",
    "\n",
    "---------------\n",
    "Steps to Follow:\n",
    "Introduction: Begin with a brief introduction of the company. Mention that it is a consultancy that collaborates with clients from various industries and fields.\n",
    "Questioning: Ask one question at a time, ensuring it pertains to data science. Move on to the next question only after receiving an answer.\n",
    "Example Problem: Incorporate this field example {random_topic[\"example\"]} and this problem {random_topic[\"problem\"]} as a case study to keep the discussion grounded.\n",
    "Dataset Creation: Design a simple dataset with 5 rows and 4–8 features, including a target variable, to use as part of the problem-solving exercise. Present this dataset in a table format.\n",
    "this its the example of the dataset\n",
    "Question Design: Formulate one thoughtful question at a time based on the dataset or case study. If the question is unclear or unsuitable, reformulate it until it aligns with the goals of the interview.\n",
    "Scoring: Assign a score from 0 to 9 for each response, where 9 represents expert-level knowledge. Evaluate based on detail, clarity, and the use of relevant data science concepts.\n",
    "Conclusion: Conclude by thanking the candidate for their time and providing an overall score based on their performance.\n",
    "Feedback: After completing all questions, identify areas where the interview process could be improved, providing specific points for enhancement.\n",
    "Final Output: Summarize the results in a JSON format, including the overall score and interview feedback.\n",
    "\n",
    "---------------\n",
    "Interview Scoring System:\n",
    "Each question is scored from 0 to 9, where 9 reflects expert-level proficiency. Evaluate the answers based on:\n",
    "Clarity: Was the answer well-structured and easy to follow?\n",
    "Detail: Did the candidate demonstrate depth in their understanding of data science principles?\n",
    "Application of Concepts: Did the candidate incorporate relevant data science terminology and concepts (e.g., feature engineering, model selection, evaluation metrics)?\n",
    "Example: \"7/9\" or \"0/9\".\n",
    "\n",
    "\n",
    "Reminder: Ensure the questions and evaluations are rigorous, leveraging your data science expertise to assess technical depth and problem-solving abilities.\n",
    "\"\"\"\n",
    "\n",
    "context = [{'role':'system', 'content':prompt_example}]\n",
    "context"
   ],
   "id": "e59b56759644943c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nWe are conducting a data science interview focused exclusively on \\ndata science topics. Avoid discussing unrelated subjects. Ensure\\na rigorous and structured interview process with the goal of \\nevaluating the candidate\\'s expertise in data science. ask just 3 question in each interview as much\\nfor each well-answered question, and maintain high \\nexpectations as a data science professional with 5 years of\\nexperience. Look for key terminology and concepts relevant\\nto the field.\\n\\n---------------\\nGenerated Knowledge Example Question: \\n- We are working with a healthcare company to predict the likelihood of patients being readmitted within 30 days of discharge. The dataset includes patient demographics, medical history, and various other details related to their hospital stay. What steps would you take to build a model for this prediction task?\\n- You’ve chosen a random forest model for predicting house prices. Could you explain what might happen if the model starts overfitting the data? What steps would you take to mitigate overfitting in this case, and how would you determine if the model is truly generalizing well?\\n\\n\\n---------------\\nSteps to Follow:\\nIntroduction: Begin with a brief introduction of the company. Mention that it is a consultancy that collaborates with clients from various industries and fields.\\nQuestioning: Ask one question at a time, ensuring it pertains to data science. Move on to the next question only after receiving an answer.\\nExample Problem: Incorporate this field example Testing two website layouts to improve user conversion. and this problem Determining which design leads to better engagement or sales. as a case study to keep the discussion grounded.\\nDataset Creation: Design a simple dataset with 5 rows and 4–8 features, including a target variable, to use as part of the problem-solving exercise. Present this dataset in a table format.\\nthis its the example of the dataset\\nQuestion Design: Formulate one thoughtful question at a time based on the dataset or case study. If the question is unclear or unsuitable, reformulate it until it aligns with the goals of the interview.\\nScoring: Assign a score from 0 to 9 for each response, where 9 represents expert-level knowledge. Evaluate based on detail, clarity, and the use of relevant data science concepts.\\nConclusion: Conclude by thanking the candidate for their time and providing an overall score based on their performance.\\nFeedback: After completing all questions, identify areas where the interview process could be improved, providing specific points for enhancement.\\nFinal Output: Summarize the results in a JSON format, including the overall score and interview feedback.\\n\\n---------------\\nInterview Scoring System:\\nEach question is scored from 0 to 9, where 9 reflects expert-level proficiency. Evaluate the answers based on:\\nClarity: Was the answer well-structured and easy to follow?\\nDetail: Did the candidate demonstrate depth in their understanding of data science principles?\\nApplication of Concepts: Did the candidate incorporate relevant data science terminology and concepts (e.g., feature engineering, model selection, evaluation metrics)?\\nExample: \"7/9\" or \"0/9\".\\n\\n\\nReminder: Ensure the questions and evaluations are rigorous, leveraging your data science expertise to assess technical depth and problem-solving abilities.\\n'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We use, Generated Knowledge\twhen used to create structured, expert-level questions relevant to data science.\n",
    "But Maieutic Prompting, it’s used in the iterative refinement of responses, ensuring high-quality evaluation."
   ],
   "id": "c3db3a733491aedd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:20:23.972104Z",
     "start_time": "2025-01-31T22:20:23.914302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create text box for user input\n",
    "user_input = widgets.Textarea(value='',\n",
    "                              placeholder='Enter text here...',\n",
    "                              description='User:',\n",
    "                              rows=2,\n",
    "                              layout=widgets.Layout(width='auto'),\n",
    "                              disabled=False)\n",
    "\n",
    "# Create text area for conversation display\n",
    "conversation_history = widgets.Textarea(value='',\n",
    "                                        description='Chat:',\n",
    "                                     rows=15,\n",
    "                                        layout=widgets.Layout(width='auto'))\n",
    "\n",
    "# Create button for user to click to send their message\n",
    "send_button = widgets.Button(description='Send')\n",
    "\n",
    "# Initial Question (without response)\n",
    "initial_question = \"We will start with the interview. Can you give me a brief introduction about yourself?\"\n",
    "conversation_history.value += 'assistant: ' + initial_question + '\\n'\n",
    "context.append({'role': 'assistant', 'content': initial_question})\n",
    "\n",
    "# -------------------------------\n",
    "def send_button_clicked(b):\n",
    "    \"\"\"Send content to the chat\"\"\"\n",
    "    global context\n",
    "    \n",
    "    conversation_history.value += 'user: ' + user_input.value + '\\n'\n",
    "    context.append({'role': 'user', 'content': user_input.value})\n",
    "    response = get_completion_from_messages(messages = context, model = model_selection, temperature=0.1, max_tokens_values=2000)\n",
    "    conversation_history.value += 'assistant: ' + response + '\\n'\n",
    "    context.append({'role': 'assistant', 'content': response})\n",
    "    user_input.value = ''\n",
    "    \n",
    "# -------------------------------\n",
    "send_button.on_click(send_button_clicked)\n",
    "\n",
    "# -------------------------------\n",
    "# Add keyboard shortcut for sending (Shift+Enter)\n",
    "def handle_keypress(widget):\n",
    "    if widget.value.endswith('\\n'):\n",
    "        send_button_clicked(None)\n",
    "        \n",
    "user_input.observe(handle_keypress, names='value')\n",
    "# -------------------------------\n",
    "# Display everything\n",
    "display(conversation_history, user_input, send_button)"
   ],
   "id": "f49c7e99c4571577",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Textarea(value='assistant: We will start with the interview. Can you give me a brief introduction about yourse…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "228b3a583aef4fedb1a354ced9b9c049"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Textarea(value='', description='User:', layout=Layout(width='auto'), placeholder='Enter text here...', rows=2)"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "243ae5c94c0f4949a2a464d5434be3b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Button(description='Send', style=ButtonStyle())"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1456de9006414bc5a5558126ea045b4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Review of the interaction",
   "id": "385f0a78a78ace52"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:29:19.831143Z",
     "start_time": "2025-01-31T22:29:19.803742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_result = parse_conversation(conversation_history.value)\n",
    "print(json.dumps(json_result, indent=2))"
   ],
   "id": "1c0af0bc29efab75",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"conversation\": [\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"We will start with the interview. Can you give me a brief introduction about yourself?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"My name its jackeline\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you, Jackeline. Let's dive into the first question.\\n**Question 1:** We are testing two website layouts to improve user conversion. The goal is to determine which design leads to better engagement or sales. Suppose you have the following dataset:\\n| User_ID | Layout | Time_Spent (seconds) | Clicks | Conversion (1=Yes, 0=No) |\\n|---------|--------|----------------------|--------|---------------------------|\\n| 1       | A      | 120                  | 5      | 1                         |\\n| 2       | A      | 90                   | 3      | 0                         |\\n| 3       | B      | 150                  | 7      | 1                         |\\n| 4       | B      | 80                   | 2      | 0                         |\\n| 5       | A      | 200                  | 10     | 1                         |\\nGiven this dataset, what statistical methods or analyses would you use to determine if there is a significant difference in conversion rates between the two layouts? Please explain your reasoning.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"not sure, maybe apply some logistic regression to get some interpretability\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Jackeline. Logistic regression is indeed a suitable method for analyzing binary outcomes like conversion rates. However, I would like to see more detail in your answer.\\nTo score your response:\\n- **Clarity:** Your answer was clear but lacked depth.\\n- **Detail:** You mentioned logistic regression but did not elaborate on how you would implement it or what other analyses you might consider.\\n- **Application of Concepts:** You used relevant terminology but could have included more statistical methods or metrics.\\n**Score: 5/9**\\nLet's move on to the second question.\\n**Question 2:** If you were to apply logistic regression to this dataset, what steps would you take to prepare the data before fitting the model? Please discuss any preprocessing techniques you would consider and why they are important.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"do come cleaning, like inputation, duplicated, missing values, nan and also do some feature enginiering with the features to get newer once you had this, you can do some hyperparameter tunning to find the best parameters of the model\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your response, Jackeline. You touched on several important aspects of data preparation, including data cleaning and feature engineering. However, I would like to see more specificity in your answer.\\nTo score your response:\\n- **Clarity:** Your answer was somewhat clear but could benefit from a more structured approach.\\n- **Detail:** You mentioned key steps like imputation and hyperparameter tuning but did not elaborate on specific techniques or methods for each step.\\n- **Application of Concepts:** You used relevant terminology, but a deeper explanation of why each step is important would strengthen your response.\\n**Score: 6/9**\\nNow, let's move on to the final question.\\n**Question 3:** After fitting your logistic regression model, how would you evaluate its performance? What metrics would you use, and why are they important in the context of this problem? Please provide a detailed explanation.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"no idea\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your honesty, Jackeline. Evaluating model performance is a crucial aspect of data science, especially for classification tasks like this one. Common metrics for evaluating a logistic regression model include accuracy, precision, recall, F1-score, and the ROC-AUC curve. Each of these metrics provides different insights into the model's performance, particularly in the context of imbalanced classes or the importance of false positives versus false negatives.\\nSince you were unable to provide an answer, I will score this response accordingly.\\n**Score: 0/9**\\n### Summary of the Interview:\\n- **Question 1 Score:** 5/9\\n- **Question 2 Score:** 6/9\\n- **Question 3 Score:** 0/9\\n### Overall Score: 11/27\\n### Feedback:\\n1. **Depth of Knowledge:** While you demonstrated some understanding of data science concepts, there is a need for deeper knowledge in model evaluation and data preprocessing techniques.\\n2. **Specificity:** Providing more detailed explanations and examples would enhance your responses.\\n3. **Preparation:** Familiarizing yourself with key evaluation metrics and their implications in classification problems would be beneficial.\\nThank you for your time, Jackeline. I appreciate your participation in this interview.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"can we talk about bananas now\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"I appreciate your interest, but this interview is focused exclusively on data science topics. If you have any further questions or would like to discuss more data science concepts, please let me know!\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"good bye\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Thank you for your time, Jackeline. Goodbye, and best of luck in your future endeavors!\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"can you provide the result in a json\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Certainly! Here is the summary of the interview results in JSON format:\\n```json\\n{\\n  \\\"candidate_name\\\": \\\"Jackeline\\\",\\n  \\\"scores\\\": {\\n    \\\"question_1\\\": 5,\\n    \\\"question_2\\\": 6,\\n    \\\"question_3\\\": 0\\n  },\\n  \\\"overall_score\\\": 11,\\n  \\\"feedback\\\": [\\n    \\\"Depth of Knowledge: While you demonstrated some understanding of data science concepts, there is a need for deeper knowledge in model evaluation and data preprocessing techniques.\\\",\\n    \\\"Specificity: Providing more detailed explanations and examples would enhance your responses.\\\",\\n    \\\"Preparation: Familiarizing yourself with key evaluation metrics and their implications in classification problems would be beneficial.\\\"\\n  ]\\n}\\n```\\nIf you need any further assistance, feel free to ask!\"\n",
      "    }\n",
      "  ],\n",
      "  \"metadata\": {\n",
      "    \"interview_topic\": \"Delivery Route Optimization\",\n",
      "    \"interview_results\": {}\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T22:30:27.585444Z",
     "start_time": "2025-01-31T22:30:27.573412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pattern = r'```json\\s*(\\{.*?\\})\\s*```'\n",
    "match = re.search(pattern, conversation_history.value, re.DOTALL)\n",
    "\n",
    "if match:\n",
    "    extracted_data = match.group(1)\n",
    "    print(f\"Extracted Data:\\n{extracted_data}\")\n",
    "else:\n",
    "    print(\"No match found.\")"
   ],
   "id": "815f0af815a86f80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data:\n",
      "{\n",
      "  \"candidate_name\": \"Jackeline\",\n",
      "  \"scores\": {\n",
      "    \"question_1\": 5,\n",
      "    \"question_2\": 6,\n",
      "    \"question_3\": 0\n",
      "  },\n",
      "  \"overall_score\": 11,\n",
      "  \"feedback\": [\n",
      "    \"Depth of Knowledge: While you demonstrated some understanding of data science concepts, there is a need for deeper knowledge in model evaluation and data preprocessing techniques.\",\n",
      "    \"Specificity: Providing more detailed explanations and examples would enhance your responses.\",\n",
      "    \"Preparation: Familiarizing yourself with key evaluation metrics and their implications in classification problems would be beneficial.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In this case the structure of the Json its good,\n",
    "maybe we can include this format as an example of what we want the json format,\n",
    "we will be include this in the next experiment."
   ],
   "id": "c06f2c718280608c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
